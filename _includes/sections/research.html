<div class="container" id="i18_research">
    <div class="row m-b-lg">
        <div class="col-lg-12 text-center">
            <div class="navy-line"></div>
            <h1>Research & Publications</h1>
        </div>
    </div>

    <div class="row">
        <div class="col-lg-12">
            <div class="research-content">
                <h3>Recent Publications</h3>
                <div class="year-section">
                    <h4>2024</h4>
                    <ul class="publications-list">
                        <li>
                            <strong>Thoidis, I.</strong>, & Goehring, T. (2024). Using deep learning to improve the intelligibility of a target speaker in noisy multi-talker environments for people with normal hearing and hearing loss. <em>The Journal of the Acoustical Society of America</em>, 156(1), 706-724.
                        </li>
                        <li>
                            <strong>Thoidis, I.</strong>, et al. (2024). Test-retest reliability of remote home-based audiometry in differing ambient noise conditions. <em>Frontiers in Audiology and Otology</em>, 2, 1371037.
                        </li>
                        <li>
                            Fletcher, M. D., et al. (2024). Improved tactile speech robustness to background noise with a dual-path recurrent neural network noise-reduction method. <em>Scientific Reports</em>, 14(1), 7357.
                        </li>
                    </ul>
                </div>

                <div class="year-section">
                    <h4>2023</h4>
                    <ul class="publications-list">
                        <li>
                            <strong>Thoidis, I.</strong>, Goehring, T. (2023). Having choices for enhancing voices: Target speaker extraction in noisy multi-talker environments using deep neural networks. <em>Virtual Conference on Computational Audiology 2023</em>.
                        </li>
                        <li>
                            <strong>Thoidis, I.</strong>, et al. (2023). Perceptual analysis of speaker embeddings for voice discrimination between machine and human listening. <em>IEEE ICASSP 2023</em>.
                        </li>
                    </ul>
                </div>

                <h3>Research Projects</h3>
                <ul class="research-projects">
                    <li>
                        <strong>Deep Learning for Speech Enhancement</strong>
                        <p>Development of novel deep learning architectures for improving speech intelligibility in complex acoustic environments.</p>
                    </li>
                    <li>
                        <strong>Mobile Audiometry Platform</strong>
                        <p>Design and implementation of a mobile-based hearing assessment system for remote and accessible hearing testing.</p>
                    </li>
                    <li>
                        <strong>Hearing Aid Algorithm Development</strong>
                        <p>Research on advanced signal processing algorithms for hearing aid applications.</p>
                    </li>
                    <li>
                        <strong>Clinical Trials and Evaluations</strong>
                        <p>Designing and conducting clinical evaluations for hearing assessment and hearing loss compensation strategies.</p>
                    </li>
                    <li>
                        <strong>Audio Semantic Analysis</strong>
                        <p>Development of advanced techniques for audio semantic analysis and speaker recognition.</p>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</div>

<style>
.research-content {
    padding: 20px;
    max-width: 800px;
    margin: 0 auto;
}

.research-content h3 {
    margin-top: 30px;
    color: #2c3e50;
}

.year-section {
    margin-bottom: 25px;
}

.year-section h4 {
    color: #1ab394;
    margin-bottom: 15px;
    font-weight: 600;
}

.publications-list {
    list-style: none;
    padding-left: 0;
}

.publications-list li {
    margin-bottom: 15px;
    padding-left: 20px;
    position: relative;
    line-height: 1.6;
}

.publications-list li:before {
    content: "â€¢";
    color: #2c3e50;
    position: absolute;
    left: 0;
}

.publications-list em {
    color: #1ab394;
    font-style: italic;
}

.research-projects {
    list-style: none;
    padding-left: 0;
}

.research-projects li {
    margin-bottom: 20px;
    padding: 15px;
    background-color: #f8f9fa;
    border-radius: 5px;
    transition: transform 0.2s ease;
}

.research-projects li:hover {
    transform: translateY(-2px);
}

.research-projects li strong {
    color: #2c3e50;
    display: block;
    margin-bottom: 5px;
}

.research-projects li p {
    margin: 0;
    color: #666;
}
</style> 